{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ê¸¸ì´ ìŠ¬ë¼ì´ë”© + overlap\n",
    "\n",
    "\tì†ì‹¤ ì—†ìŒ, ì•ˆì •ì \n",
    "\të¬¸ì¥ ì¤‘ê°„ ì˜ë¦¼\n",
    "\të…¼ë¬¸/ì˜í•™ ì¦ë¡€\n",
    "\n",
    "2. ë¬¸ì¥ ê¸°ë°˜ Sentence-based Chunking  -> kss, spacy, NLTK ë¬¸ì¥ë¶„ë¦¬ê¸° \n",
    "(ê·œì¹™ ê¸°ë°˜ + ë¬¸ì¥ ë¶„ë¦¬ê¸°)\n",
    "\n",
    "    âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\tìì—°ì–´ ì„¤ëª…ì´ ë§ì€ ë¬¸ì„œ\n",
    "\tâ€¢\të¬¸ì¥ ì¤‘ì‹¬ êµ¬ì¡°(ë¸”ë¡œê·¸, ì„¤ëª…ì„œ, ë¦¬í¬íŠ¸, êµê³¼ì„œ ë“±)\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\të¬¸ì¥ ë¶„ë¦¬ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ\n",
    "\tâ€¢\tì¼ë¶€ ì–´ë ¤ìš´ ë¬¸ì¥ êµ¬ì¡°ì—ì„œ ë¶„ë¦¬ê°€ ì–´ìƒ‰í•  ìˆ˜ ìˆìŒ\n",
    "\t\n",
    "\t\t##kss ë‚´ë¶€ ë™ì‘ êµ¬ì¡°(ê³µì‹ ë¬¸í—Œ ê¸°ë°˜)\n",
    "\t\t\tâ€¢\tí•œêµ­ì–´ ì¢…ê²° ì–´ë¯¸ ê·œì¹™\n",
    "\t\t\tâ€¢\të§ˆì¹¨í‘œ/ë”°ì˜´í‘œ/ê´„í˜¸ ì¡°í•©ì— ëŒ€í•œ ë£°\n",
    "\t\t\tâ€¢\tìˆ«ì/ì•½ì–´/ë¦¬ìŠ¤íŠ¸ í‘œê¸° ì˜ˆì™¸ ì²˜ë¦¬\n",
    "\t\t\tâ€¢\tâ€œë‹¤.â€/â€œìš”.â€/â€œí–ˆë‹¤.â€ íŒ¨í„´ í•™ìŠµ\n",
    "\t\t\tâ€¢\të¬¸ì¥ ê²½ê³„ í›„ë³´ë¥¼ ë†“ê³  í†µê³„ ëª¨ë¸ì´ í™•ë¥  íŒë‹¨\n",
    "\n",
    "\t\tì¦‰:\n",
    "\n",
    "\t\tkssì˜ í•µì‹¬ ëª©í‘œ = â€œë¬¸ì¥ì´ ì–´ë””ì„œ ëë‚˜ëŠ”ì§€â€ ì˜ˆì¸¡\n",
    "\n",
    "\t\tê·¸ë¦¬ê³  ì´ ê³¼ì •ì—ì„œ ê¸¸ì´, ì˜ë¯¸, ìŠ¬ë¼ì´ë”© ì „í˜€ ì•ˆ ì”€.\n",
    "\n",
    "3. ë¬¸ë‹¨ ê¸°ë°˜\n",
    "    âœ” íŠ¹ì§•\n",
    "\tâ€¢\të¹ˆ ì¤„(\\n\\n) ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ì„ ìª¼ê°œê¸°\n",
    "\tâ€¢\të¬¸ë‹¨ ìì²´ê°€ ì˜ë¯¸ ë©ì–´ë¦¬ë¼ RAG ê²€ìƒ‰ í’ˆì§ˆ ê³ ì •\n",
    "\tâ€¢\të¬¸ì„œ êµ¬ì¡°ê°€ ê¹¨ë—í•œ ê²½ìš°ì—” ìµœì„ \n",
    "\tâ€¢\të³´í†µ PDF â†’ í…ìŠ¤íŠ¸ ë³€í™˜í˜• ë¬¸ì„œì—ì„œ ì •ë‹µ\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\têµê³¼ì„œ, ë³´ê³ ì„œ, ë§¤ë‰´ì–¼, ë…¼ë¬¸ (ë¬¸ë‹¨ ëª…í™•í•œ ê²½ìš°)\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\të„ˆì˜ ë°ì´í„°ì²˜ëŸ¼ ë¬¸ë‹¨ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš° â†’ 1ë©ì–´ë¦¬ë¡œ ë‚˜ì˜´\n",
    "\tâ€¢\t1ë¬¸ë‹¨ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì•¼ í•¨ â†’ ì†ì‹¤ ê°€ëŠ¥ì„±\n",
    "\n",
    "\n",
    "4. ì œëª©/í—¤ë” ê¸°ë°˜\n",
    "    âœ” íŠ¹ì§•\n",
    "\tâ€¢\tâ€œì œëª©/ì†Œì œëª©â€ì„ ê°ì§€í•˜ì—¬ ì„¹ì…˜ ë‹¨ìœ„ë¡œ ë¨¼ì € split\n",
    "\tâ€¢\tì˜ˆ:\n",
    "\tâ€¢\t### 1. Introduction\n",
    "\tâ€¢\t### Case 2 â€“ Diagnosis\n",
    "\tâ€¢\t2) ê²€ì‚¬í•­ëª©\n",
    "\tâ€¢\t- ì¦ìƒ ë“±\n",
    "\tâ€¢\tê° ì„¹ì…˜ ì•ˆì—ì„œ ë‹¤ì‹œ ê¸¸ì´ ê¸°ì¤€ ìŠ¬ë¼ì´ë”© ì ìš©\n",
    "\tâ€¢\têµ¬ì¡° + ë‚´ìš© ë‘˜ ë‹¤ ë³´ì¡´\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\tê·œì¹™ ìˆëŠ” í…ìŠ¤íŠ¸ (ë§¤ë‰´ì–¼, ë³´ê³ ì„œ, ì—°êµ¬ ë¬¸ì„œ, ë©”ë‰´íŒ ë“±)\n",
    "\tâ€¢\tì œëª© íŒ¨í„´ì´ ëª…í™•í•œ JSON ë¼ë²¨ í˜•ì‹\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\tì œëª© íŒ¨í„´ì„ ë§ì¶”ì§€ ëª»í•˜ë©´ split ì‹¤íŒ¨\n",
    "\tâ€¢\tì˜í•™ ì¦ë¡€ì²˜ëŸ¼ â€œë¬¸ë‹¨ì´ ë°”ë¡œ ë³¸ë¬¸ìœ¼ë¡œ ì‹œì‘â€í•˜ëŠ” ì¼€ì´ìŠ¤ëŠ” êµ¬ì¡°ê°€ ëœí•¨\n",
    "\n",
    "    \n",
    "5. ì˜ë¯¸ ê¸°ë°˜(semantic)\n",
    " \n",
    "\n",
    " 1,2 ìˆœìœ¼ë¡œ ì ì ˆí•˜ë‹¤.\n",
    " â†’ ì˜ë¯¸ê°€ ê¸‰ê²©í•˜ê²Œ ë°”ë€ŒëŠ” ì§€ì ì„ ìë™ ê°ì§€í•´ split\n",
    "\n",
    "âœ” íŠ¹ì§•\n",
    "\tâ€¢\të¬¸ì¥ì„ ì„ë² ë”©í•´ì„œ\n",
    "\tâ€¢\tì´ì „ ë¬¸ì¥ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸‰í•˜ë½ ì‹œ â€œìƒˆ ì²­í¬ ì‹œì‘â€\n",
    "\tâ€¢\tâ€œí† í”½ ì „í™˜ í¬ì¸íŠ¸â€ë¥¼ ìë™ìœ¼ë¡œ ì¸ì‹\n",
    "\tâ€¢\tëŒ€ê·œëª¨ ë¬¸ì„œì—ì„œë„ ì˜ë¯¸ ì¼ê´€ì„±ì„ ë³´ì¥í•˜ëŠ” ìµœì²¨ë‹¨ ë°©ì‹\n",
    "\tâ€¢\tLLMê³¼ì˜ ê¶í•© ì™„ë²½í•¨\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\tí•™ìˆ ìë£Œ / ì—¬ëŸ¬ ì¦ë¡€ê°€ ì—°ì†ëœ ë¬¸ì„œ / ë§¤ë‰´ì–¼ ì±•í„° ë“±\n",
    "\tâ€¢\tì˜ë¯¸ ë©ì–´ë¦¬ë¥¼ ìŠ¤ìŠ¤ë¡œ ì´ì–´ì•¼ í•˜ëŠ” ì •êµí•œ RAG êµ¬ì¶• ì‹œ\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\tê°€ì¥ ëŠë¦¼\n",
    "\tâ€¢\tsentence transformer í•„ìš”\n",
    "\tâ€¢\têµ¬í˜„ ë‚œì´ë„ â†‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê¸°ë³¸: ë‘ ì¤„ ì´ìƒ ê°œí–‰(ë¹ˆ ì¤„) ê¸°ì¤€ ë¶„ë¦¬ (r\"\\n{2,}\")\n",
    "#    - ë„ˆë¬´ ì§§ì€/ê¸´ ì¡°ê° í•„í„°ë§ -> ì‹¤ì œ ë¬¸ì„œì—ì„œ ì†ì‹¤ë¥  ë„ˆë¬´í¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] JSON íŒŒì¼ 212ê°œ ì¤‘ 2ê°œ ë¯¸ë¦¬ë³´ê¸°\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/ì‘ ê³¼ì œí•´/ìì—°ì–´ì²˜ë¦¬/rag/data/TS_á„†á…¡á†¯á„†á…®á†¼á„á…µá„ƒá…¦á„‹á…µá„á…¥_á„‹á…¡á†«á„€á…ª/0e8bca31-e151-11ef-4bb1-00155dced605.json\n",
      "  - title      : 40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "  - department : ì•ˆê³¼\n",
      "  - text len   : 4526 chars\n",
      "  â†’ ì²­í¬ 1ê°œ ìƒì„±\n",
      "  â†’ ì›ë³¸ ì €ì¥: 0e8bca31-e151-11ef-4bb1-00155dced605_original.txt\n",
      "  â†’ ì²­í¬ ì €ì¥: 1ê°œ (ì˜ˆ: ['chunk_preview_output/0e8bca31-e151-11ef-4bb1-00155dced605_chunk_0.txt'])\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ì›ë³¸ text] (ì• 300ì)\n",
      "40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œ í•œ ë§ˆë¦¬ê°€ 1ì£¼ì¼ ë™ì•ˆ ê²°ë§‰ ì¶©í˜ˆê³¼ ëˆˆ ë¶„ë¹„ë¬¼ì˜ ë³‘ë ¥ì„ ê°€ì§€ê³  ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ì™¼ìª½ ëˆˆ. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ê°€ ì—†ì—ˆí•˜ì˜€ë‹¤. ìŠ¬ë¦¿ ë¨í”„ ìƒì²´ í˜„ë¯¸ê²½ ê°ë§‰ ë¶€ì¢…, ì„¬ëª¨ í™ì¡°, ìˆ˜ì„± ë°œì ì´ ë“œëŸ¬ë‚¬í•˜ì˜€ë‹¤. ì•ˆêµ¬ ë‚´ì••ì€ 68 mmHgì˜€ìŠµë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥í•œ ìë£Œì— ë”°ë¥´ë©´, ë…¹ë‚´ì¥ê³¼ í¬ë„ë§‰ì—¼ ì§„ë‹¨ì´ ë‚´ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. ì‚¬ë¡€ ë³´ê³  ë¯¸ì£¼ë¦¬ì£¼ ì½œëŸ¼ë¹„ì•„ 65211, ë¯¸êµ­ ê³ ë‹ˆì˜¤ë””ì¦ˆê²Œë„¤ì‹œìŠ¤(goniodysgenesis), ...\n",
      "\n",
      "[ì²­í¬ 0] (ì• 300ì)\n",
      "40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œ í•œ ë§ˆë¦¬ê°€ 1ì£¼ì¼ ë™ì•ˆ ê²°ë§‰ ì¶©í˜ˆê³¼ ëˆˆ ë¶„ë¹„ë¬¼ì˜ ë³‘ë ¥ì„ ê°€ì§€ê³  ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ì™¼ìª½ ëˆˆ. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ê°€ ì—†ì—ˆí•˜ì˜€ë‹¤. ìŠ¬ë¦¿ ë¨í”„ ìƒì²´ í˜„ë¯¸ê²½ ê°ë§‰ ë¶€ì¢…, ì„¬ëª¨ í™ì¡°, ìˆ˜ì„± ë°œì ì´ ë“œëŸ¬ë‚¬í•˜ì˜€ë‹¤. ì•ˆêµ¬ ë‚´ì••ì€ 68 mmHgì˜€ìŠµë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥í•œ ìë£Œì— ë”°ë¥´ë©´, ë…¹ë‚´ì¥ê³¼ í¬ë„ë§‰ì—¼ ì§„ë‹¨ì´ ë‚´ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. ì‚¬ë¡€ ë³´ê³  ë¯¸ì£¼ë¦¬ì£¼ ì½œëŸ¼ë¹„ì•„ 65211, ë¯¸êµ­ ê³ ë‹ˆì˜¤ë””ì¦ˆê²Œë„¤ì‹œìŠ¤(goniodysgenesis), ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 0] len=1200\n",
      "40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œ í•œ ë§ˆë¦¬ê°€ 1ì£¼ì¼ ë™ì•ˆ ê²°ë§‰ ì¶©í˜ˆê³¼ ëˆˆ ë¶„ë¹„ë¬¼ì˜ ë³‘ë ¥ì„ ê°€ì§€ê³  ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ì™¼ìª½ ëˆˆ. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ê°€ ì—†ì—ˆí•˜ì˜€ë‹¤. ìŠ¬ë¦¿ ë¨í”„ ìƒì²´ í˜„ë¯¸ê²½ ê°ë§‰ ë¶€ì¢…, ì„¬ëª¨ í™ì¡°, ìˆ˜ì„± ë°œì ì´ ë“œëŸ¬ë‚¬í•˜ì˜€ë‹¤. ì•ˆêµ¬ ë‚´ì••ì€ 68 mmHgì˜€ìŠµë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥í•œ ìë£Œì— ë”°ë¥´ë©´, ë…¹ë‚´ì¥ê³¼ í¬ë„ë§‰ì—¼ ì§„ë‹¨ì´ ë‚´ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. ì‚¬ë¡€ ë³´ê³  ë¯¸ì£¼ë¦¬ì£¼ ì½œëŸ¼ë¹„ì•„ 65211, ë¯¸êµ­ ê³ ë‹ˆì˜¤ë””ì¦ˆê²Œë„¤ì‹œìŠ¤(goniodysgenesis), í›„ë°© êµì°©(pos terior synechia), ê·¸ë¦¬ê³  íŠ¸ë¼ë² í˜ë¼ ë§ì‚¬(trabecular meshwork)ì˜ ìƒ‰ì†Œ ë¶„ì‚°ì˜ íš¨ê³¼. ì´ê²ƒì€ ì²« ë²ˆì§¸ ì¼ì°¨ ë³´ê³ ì…ë‹ˆë‹¤. ì§„ë—ê°œì—ì„œ ì„ \n",
      "...\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/ì‘ ê³¼ì œí•´/ìì—°ì–´ì²˜ë¦¬/rag/data/TS_á„†á…¡á†¯á„†á…®á†¼á„á…µá„ƒá…¦á„‹á…µá„á…¥_á„‹á…¡á†«á„€á…ª/d24ea6b3-e150-11ef-bc07-00155dced605.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "SAVE_DIR = Path(\"./chunk_preview_output\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_text(filename: str, content: str):\n",
    "    path = SAVE_DIR / filename\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return str(path)\n",
    "\n",
    "def debug_preview_and_save(\n",
    "    data_dir: Path = DATA_DIR,\n",
    "    text_field: str = \"disease\",\n",
    "    max_chunk_chars: int = 1200,\n",
    "    min_len: int = 30,\n",
    "    max_files: int = 3,\n",
    "    max_chunks_per_file: int = 3,\n",
    "):\n",
    "    pattern = str(data_dir / \"**\" / \"*.json\")\n",
    "    file_paths = glob.glob(pattern, recursive=True)\n",
    "\n",
    "    print(f\"[debug] JSON íŒŒì¼ {len(file_paths)}ê°œ ì¤‘ {max_files}ê°œ ë¯¸ë¦¬ë³´ê¸°\\n\")\n",
    "\n",
    "    for fp in file_paths[:max_files]:\n",
    "        print(\"#\" * 80)\n",
    "        print(f\"[FILE] {fp}\")\n",
    "\n",
    "        for obj in _iter_json(fp):\n",
    "            text = str(obj.get(text_field, \"\")).strip()\n",
    "            title = obj.get(\"title\", \"N/A\")\n",
    "            dept  = obj.get(\"department\", \"N/A\")\n",
    "\n",
    "            print(f\"  - title      : {title}\")\n",
    "            print(f\"  - department : {dept}\")\n",
    "            print(f\"  - text len   : {len(text)} chars\")\n",
    "\n",
    "            if not text:\n",
    "                print(\"  (âš ï¸ disease ë¹„ì–´ ìˆìŒ)\\n\")\n",
    "                continue\n",
    "\n",
    "            # ğŸ’¾ ì›ë³¸ ì €ì¥\n",
    "            original_name = Path(fp).stem + \"_original.txt\"\n",
    "            save_text(original_name, text)\n",
    "\n",
    "            chunks = _chunk_text(text, max_chunk_chars=max_chunk_chars, min_len=min_len)\n",
    "\n",
    "            # ğŸ’¾ ê° ì²­í¬ ì €ì¥\n",
    "            chunk_paths = []\n",
    "            for i, ch in enumerate(chunks):\n",
    "                chunk_name = f\"{Path(fp).stem}_chunk_{i}.txt\"\n",
    "                p = save_text(chunk_name, ch)\n",
    "                chunk_paths.append(p)\n",
    "\n",
    "            print(f\"  â†’ ì²­í¬ {len(chunks)}ê°œ ìƒì„±\")\n",
    "            print(f\"  â†’ ì›ë³¸ ì €ì¥: {original_name}\")\n",
    "            print(f\"  â†’ ì²­í¬ ì €ì¥: {len(chunk_paths)}ê°œ (ì˜ˆ: {chunk_paths[:1]})\\n\")\n",
    "\n",
    "            # ğŸ–¥ï¸ Notebook ì „/í›„ ë¹„êµ ì¶œë ¥\n",
    "            print(\"-\" * 60)\n",
    "            print(\"[ì›ë³¸ text] (ì• 300ì)\")\n",
    "            print(text[:300] + (\"...\\n\" if len(text) > 300 else \"\\n\"))\n",
    "\n",
    "            print(\"[ì²­í¬ 0] (ì• 300ì)\")\n",
    "            if chunks:\n",
    "                print(chunks[0][:300] + (\"...\\n\" if len(chunks[0]) > 300 else \"\\n\"))\n",
    "\n",
    "            for i, ch in enumerate(chunks[:max_chunks_per_file]):\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"[CHUNK {i}] len={len(ch)}\")\n",
    "                print(ch[:400] + (\"\\n...\\n\" if len(ch) > 400 else \"\\n\"))\n",
    "                \n",
    "debug_preview_and_save(\n",
    "    data_dir=DATA_DIR,\n",
    "    text_field=\"disease\",\n",
    "    max_files=2,\n",
    "    max_chunks_per_file=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 2.ğŸ“ ì•Œê³ ë¦¬ì¦˜ êµ¬ì¡°\n",
    "\t1.\tí…ìŠ¤íŠ¸ ê°œí–‰ ì •ê·œí™”\n",
    "â†’ Windows/macOS ë“± ê°œí–‰ ì°¨ì´ë¥¼ ì œê±°í•˜ê³  \\nìœ¼ë¡œ í†µì¼\n",
    "\t2.\të¹ˆ ì¤„(\\n\\n) ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ì„ 1ì°¨ ë¶„ë¦¬\n",
    "â†’ ê¸´ ë¬¸ì„œë¼ë„ ìµœì†Œí•œì˜ ë¬¸ë‹¨ êµ¬ì¡°ëŠ” ìœ ì§€\n",
    "\t3.\tê° ë¬¸ë‹¨ì— ëŒ€í•´:\n",
    "\tâ€¢\tê¸¸ì´ê°€ 1200ì ì´í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\tâ€¢\tê¸¸ì´ê°€ 1200ì ì´ˆê³¼ë©´\n",
    "â†’ ì—¬ëŸ¬ ê°œì˜ 1200ì ì²­í¬ë¡œ ì˜ë¼ëƒ„\n",
    "â†’ ê° ì²­í¬ëŠ” 200ì ì •ë„ ì• ì²­í¬ì˜ ëë¶€ë¶„ì„ ê²¹ì³ì„œ(overlap) í¬í•¨\n",
    "\t4.\tëª¨ë“  ì²­í¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
    "â†’ ì›ë³¸ ë‚´ìš© ì†ì‹¤ ì—†ìŒ -->\n",
    "1ï¸âƒ£ Length-based Sliding Window (ê¸¸ì´ ê¸°ë°˜ + Overlap)\n",
    "\n",
    "â†’ ì§€ê¸ˆ ë„¤ê°€ ì ìš©í•œ ë°©ì‹. ì˜í•™/ë…¼ë¬¸í˜• í…ìŠ¤íŠ¸ì—ì„œ ì†ì‹¤ ì—†ëŠ” ìµœê°• ê¸°ë³¸ê¸°\n",
    "\n",
    "âœ” íŠ¹ì§•\n",
    "\tâ€¢\tì¤„ë°”ê¿ˆ/ë¬¸ë‹¨ êµ¬ì¡°ê°€ ì—‰ë§ì´ê±°ë‚˜ ì•„ì˜ˆ ì—†ì–´ë„ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™\n",
    "\tâ€¢\tì›ë³¸ ì†ì‹¤ ì—†ìŒ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ëª¨ë“  ë²”ìœ„ ì»¤ë²„)\n",
    "\tâ€¢\tRAG ê²€ìƒ‰ ì•ˆì •ì„± ë§¤ìš° ì¢‹ìŒ\n",
    "\tâ€¢\têµ¬í˜„ ë‹¨ìˆœ + ì „ì²˜ë¦¬ ì†ë„ ë¹ ë¦„\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\tì˜í•™ ì¦ë¡€ / ì—°êµ¬ ë³´ê³ ì„œ / ë…¼ë¬¸í˜• í…ìŠ¤íŠ¸\n",
    "\tâ€¢\tOCR / ì›¹í¬ë¡¤ë§ì²˜ëŸ¼ ë¬¸ë‹¨ êµ¬ì¡°ê°€ ë¶ˆëª…í™•í•œ í…ìŠ¤íŠ¸\n",
    "\tâ€¢\tâ€œì§€ê¸ˆ ë„¤ ë°ì´í„° ê·¸ëŒ€ë¡œâ€\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\toverlap ë•Œë¬¸ì— ì²­í¬ ìˆ˜ê°€ ëŠ˜ì–´ë‚  ìˆ˜ ìˆìŒ\n",
    "\tâ€¢\të¬¸ì¥ ì¤‘ê°„ì—ì„œ ëŠê¸¸ ìˆ˜ ìˆìŒ\n",
    "\n",
    "max_chunk_chars=1200, overlap=200ì¼ ë•Œ:\n",
    "\tâ€¢\tCHUNK 0: 0 ~ 1200\n",
    "\tâ€¢\tCHUNK 1: 1000 ~ 2200\n",
    "\tâ€¢\tCHUNK 2: 2000 ~ 3200\n",
    "\tâ€¢\tCHUNK 3: 3000 ~ 4526\n",
    "\n",
    "\të¬¸ë‹¨ ê¸¸ì´ = 2000ì\n",
    "max = 800\n",
    "overlap = 200\n",
    "\n",
    "CHUNK1: 0~800\n",
    "CHUNK2: 600~1400\n",
    "CHUNK3: 1200~2000\n",
    "\n",
    "\tâ€¢\të³´í†µ overlap_charsëŠ” max_chunk_charsì˜ 10~30% ì •ë„ê°€ ë¬´ë‚œ:\n",
    "\tâ€¢\t1200ì´ë©´ 150~300 ì •ë„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] JSON íŒŒì¼ 212ê°œ ì¤‘ 2ê°œ ë¯¸ë¦¬ë³´ê¸°\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/ì‘ ê³¼ì œí•´/ìì—°ì–´ì²˜ë¦¬/rag/data/TS_á„†á…¡á†¯á„†á…®á†¼á„á…µá„ƒá…¦á„‹á…µá„á…¥_á„‹á…¡á†«á„€á…ª/0e8bca31-e151-11ef-4bb1-00155dced605.json\n",
      "  - title      : 40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "  - department : ì•ˆê³¼\n",
      "  - text len   : 4526 chars\n",
      "  â†’ ì²­í¬ 5ê°œ ìƒì„±\n",
      "  â†’ ì›ë³¸ ì €ì¥: 0e8bca31-e151-11ef-4bb1-00155dced605_original.txt\n",
      "  â†’ ì²­í¬ ì €ì¥: 5ê°œ (ì˜ˆ: ['chunk_preview_output/0e8bca31-e151-11ef-4bb1-00155dced605_chunk_0.txt'])\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ì›ë³¸ text] (ì• 300ì)\n",
      "40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œ í•œ ë§ˆë¦¬ê°€ 1ì£¼ì¼ ë™ì•ˆ ê²°ë§‰ ì¶©í˜ˆê³¼ ëˆˆ ë¶„ë¹„ë¬¼ì˜ ë³‘ë ¥ì„ ê°€ì§€ê³  ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ì™¼ìª½ ëˆˆ. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ê°€ ì—†ì—ˆí•˜ì˜€ë‹¤. ìŠ¬ë¦¿ ë¨í”„ ìƒì²´ í˜„ë¯¸ê²½ ê°ë§‰ ë¶€ì¢…, ì„¬ëª¨ í™ì¡°, ìˆ˜ì„± ë°œì ì´ ë“œëŸ¬ë‚¬í•˜ì˜€ë‹¤. ì•ˆêµ¬ ë‚´ì••ì€ 68 mmHgì˜€ìŠµë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥í•œ ìë£Œì— ë”°ë¥´ë©´, ë…¹ë‚´ì¥ê³¼ í¬ë„ë§‰ì—¼ ì§„ë‹¨ì´ ë‚´ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. ì‚¬ë¡€ ë³´ê³  ë¯¸ì£¼ë¦¬ì£¼ ì½œëŸ¼ë¹„ì•„ 65211, ë¯¸êµ­ ê³ ë‹ˆì˜¤ë””ì¦ˆê²Œë„¤ì‹œìŠ¤(goniodysgenesis), ...\n",
      "\n",
      "[ì²­í¬ 0] (ì• 300ì)\n",
      "40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œ í•œ ë§ˆë¦¬ê°€ 1ì£¼ì¼ ë™ì•ˆ ê²°ë§‰ ì¶©í˜ˆê³¼ ëˆˆ ë¶„ë¹„ë¬¼ì˜ ë³‘ë ¥ì„ ê°€ì§€ê³  ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ì™¼ìª½ ëˆˆ. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ê°€ ì—†ì—ˆí•˜ì˜€ë‹¤. ìŠ¬ë¦¿ ë¨í”„ ìƒì²´ í˜„ë¯¸ê²½ ê°ë§‰ ë¶€ì¢…, ì„¬ëª¨ í™ì¡°, ìˆ˜ì„± ë°œì ì´ ë“œëŸ¬ë‚¬í•˜ì˜€ë‹¤. ì•ˆêµ¬ ë‚´ì••ì€ 68 mmHgì˜€ìŠµë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥í•œ ìë£Œì— ë”°ë¥´ë©´, ë…¹ë‚´ì¥ê³¼ í¬ë„ë§‰ì—¼ ì§„ë‹¨ì´ ë‚´ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. ì‚¬ë¡€ ë³´ê³  ë¯¸ì£¼ë¦¬ì£¼ ì½œëŸ¼ë¹„ì•„ 65211, ë¯¸êµ­ ê³ ë‹ˆì˜¤ë””ì¦ˆê²Œë„¤ì‹œìŠ¤(goniodysgenesis), ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 0] len=1200\n",
      "40 .ì§„ë—ê°œì—ì„œì˜ ê³ ë‹ˆì˜¤ë””ìŠ¤ê²Œë„¤ì‹œìŠ¤ ê´€ë ¨ ë…¹ë‚´ì¥\n",
      "10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œ í•œ ë§ˆë¦¬ê°€ 1ì£¼ì¼ ë™ì•ˆ ê²°ë§‰ ì¶©í˜ˆê³¼ ëˆˆ ë¶„ë¹„ë¬¼ì˜ ë³‘ë ¥ì„ ê°€ì§€ê³  ë‚´ì›í–ˆìŠµë‹ˆë‹¤. ì™¼ìª½ ëˆˆ. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ê°€ ì—†ì—ˆí•˜ì˜€ë‹¤. ìŠ¬ë¦¿ ë¨í”„ ìƒì²´ í˜„ë¯¸ê²½ ê°ë§‰ ë¶€ì¢…, ì„¬ëª¨ í™ì¡°, ìˆ˜ì„± ë°œì ì´ ë“œëŸ¬ë‚¬í•˜ì˜€ë‹¤. ì•ˆêµ¬ ë‚´ì••ì€ 68 mmHgì˜€ìŠµë‹ˆë‹¤. ì´ìš© ê°€ëŠ¥í•œ ìë£Œì— ë”°ë¥´ë©´, ë…¹ë‚´ì¥ê³¼ í¬ë„ë§‰ì—¼ ì§„ë‹¨ì´ ë‚´ë ¤ì¡ŒìŠµë‹ˆë‹¤. ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. ì‚¬ë¡€ ë³´ê³  ë¯¸ì£¼ë¦¬ì£¼ ì½œëŸ¼ë¹„ì•„ 65211, ë¯¸êµ­ ê³ ë‹ˆì˜¤ë””ì¦ˆê²Œë„¤ì‹œìŠ¤(goniodysgenesis), í›„ë°© êµì°©(pos terior synechia), ê·¸ë¦¬ê³  íŠ¸ë¼ë² í˜ë¼ ë§ì‚¬(trabecular meshwork)ì˜ ìƒ‰ì†Œ ë¶„ì‚°ì˜ íš¨ê³¼. ì´ê²ƒì€ ì²« ë²ˆì§¸ ì¼ì°¨ ë³´ê³ ì…ë‹ˆë‹¤. ì§„ë—ê°œì—ì„œ ì„ \n",
      "...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 1] len=1199\n",
      "ì•ˆì•• ìƒìŠ¹ì— ë”°ë¥¸ ì‹œì‹ ê²½ ì†ìƒ. 10ì„¸ ëœ ì˜¨ì „í•œ ì•”ì»· ì§„ë—ê°œì— ê²Œ 1ì£¼ì¼ê°„ì˜ ë³‘ë ¥ì„ ë³´ê³ í–ˆìŠµë‹ˆë‹¤. ê²°ë§‰ ì¶©í˜ˆê³¼ ì™¼ìª½ ëˆˆì˜ ëˆˆ ë¶„ë¹„ë¬¼(OS). ë‚´ì› ì‹œ, OSì—ì„œ ì•ˆêµ¬ì—¼, ì ì•¡ ë¶„ë¹„ë¬¼, ê²½ë¯¸í•œ ì•ˆê²€ ê²½ ë ¨ì´ ë¶„ëª…í–ˆí•˜ì˜€ë‹¤. ìœ„í˜‘ ë°˜ì‘, ëˆˆë¶€ì‹¬ ë°˜ì‚¬, ì§ì ‘ ë™ê³µ ë¹› ë°˜ì‚¬ (PLR)ì€ OSì—ì„œ ì—†ì—ˆí•˜ì˜€ë‹¤. OSì—ì„œ ì˜¤ë¥¸ìª½ ëˆˆ(OD)ìœ¼ë¡œ ê°€ëŠ” ê°„ì ‘ PLRì€ ë˜í•œ ê²°ì—¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìŠ¬ë¦¿ë¨í”„ ìƒì²´í˜„ë¯¸ê²½(HS 7 000; Huvitz Co., Ltd., Korea)ì—ì„œ, OSì—ì„œ ëšœë ·í•œ ìƒê°•ë§‰ í˜ˆê´€ ì£¼ì…, í™•ì‚°ì„± ê°ë§‰ ë¶€ì¢… ë° ê°ë§‰ ì£¼ìœ„ ì„¬ëª¨ í™ì¡°ê°€ ê´€ì°°ë˜ì—ˆìœ¼ ë©°, ì¤‘ë“±ë„(3+)ì˜ í”Œë ˆì–´ì™€ í™ì±„ í™ì±„ í™ì¡°ì¦ ë° í™ì±„ ë´„ë² ë¥¼ ë™ë°˜í•œ ë™ê³µ í™•ì¥ì¦ì´ ê´€ì°°ë˜ì—ˆ ìŠµë‹ˆë‹¤. í”Œë£¨ì˜¤ë ˆì„¸ì¸ ì—¼ìƒ‰ ê°ë§‰ ê²°í•¨ì´ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•˜í•˜ì˜€ë‹¤. IO\n",
      "...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 2] len=1200\n",
      "res Merck Sharp & Dohme Cibret, í”„ë‘ìŠ¤; q8h), ii) 0.5% ë ˆë³´í”Œë¡ì‚¬ì‹ (CravitÂ®; Santen Pharmaceutical ì£¼ì‹íšŒì‚¬, ì¼ë³¸ ì˜¤ì‚¬ì¹´; q8h), ë° iii) 1% í”„ë ˆë“œë‹ˆì†”ë¡  ì•„ì„¸í…Œì´íŠ¸ (Pred ForteÂ®; Allergan Pharmaceuticals, Ireland; q6h). ODì˜ ì˜ˆë°©ì  ì¹˜ ë£ŒëŠ” 0.5% Betaxololë¡œ êµ¬ì„±ë¨ (BetopticÂ®; Alc on couvreur NV, ë²¨ê¸°ì— Puurs; q12h). ê°œëŠ” ì²« ì§„ë£Œ í›„ 1ì£¼ì¼ í›„ì— ì¬ê²€ì§„ì„ ë°›ì•˜í•˜ì˜€ë‹¤. ìš°ë¦¬ ë³‘ì›ì—ì„œ. ì£¼ì¸ì€ ì²« ë²ˆì§¸ ì§„ë£Œì™€ ë¹„êµí–ˆì„ ë•Œ ì˜ë¯¸ ìˆëŠ” ê°œì„ ì´ ì—†ë‹¤ê³  ë³´ê³  í–ˆìŠµë‹ˆë‹¤. ì§‘ì—ì„œ êµ­ì†Œ ì•½ë¬¼ì„ ì£¼ì…í•˜ëŠ” ë° ì–´ë ¤ì›€ì´ ìˆì—ˆí•˜ì˜€ë‹¤. í•µì¶œìˆ ì´ ê¶Œì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì†Œìœ ìì˜\n",
      "...\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/ì‘ ê³¼ì œí•´/ìì—°ì–´ì²˜ë¦¬/rag/data/TS_á„†á…¡á†¯á„†á…®á†¼á„á…µá„ƒá…¦á„‹á…µá„á…¥_á„‹á…¡á†«á„€á…ª/d24ea6b3-e150-11ef-bc07-00155dced605.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Dict, Iterable\n",
    "\n",
    "# ========== 0. ë°ì´í„° ê²½ë¡œ (ë„ˆì˜ ì‹¤ì œ ê²½ë¡œ) ==========\n",
    "DATA_DIR = Path(\"/Users/test/ì‘ ê³¼ì œí•´/ìì—°ì–´ì²˜ë¦¬/rag/data\")\n",
    "\n",
    "# ========== 1. JSON ì½ê¸° ==========\n",
    "def _iter_json(file_path: str) -> Iterable[Dict]:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            obj = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            return\n",
    "    if isinstance(obj, dict):\n",
    "        yield obj\n",
    "    elif isinstance(obj, list):\n",
    "        for o in obj:\n",
    "            if isinstance(o, dict):\n",
    "                yield o\n",
    "\n",
    "\n",
    "# ========== 2. ì†ì‹¤ ì—†ëŠ” ì²­í‚¹ í•¨ìˆ˜ (overlap í¬í•¨) ==========\n",
    "def _chunk_text(\n",
    "    text: str,\n",
    "    max_chunk_chars: int = 1200,\n",
    "    min_len: int = 30,\n",
    "    overlap_chars: int = 200   # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„\n",
    ") -> List[str]:\n",
    "\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    raw_chunks = [c.strip() for c in re.split(r\"\\n{2,}\", text)]\n",
    "    \n",
    "    clean: List[str] = []\n",
    "\n",
    "    for c in raw_chunks:\n",
    "        if not c or len(c) < min_len:\n",
    "            continue\n",
    "\n",
    "        # Case 1: ë¸”ë¡ì´ max_chunk_chars ì´í•˜ â†’ ê·¸ëŒ€ë¡œ\n",
    "        if len(c) <= max_chunk_chars:\n",
    "            clean.append(c)\n",
    "            continue\n",
    "\n",
    "        # Case 2: ë¸”ë¡ì´ ë„ˆë¬´ ê¹€ â†’ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸° + overlap\n",
    "        step = max_chunk_chars - overlap_chars\n",
    "        if step <= 0:\n",
    "            step = max_chunk_chars   # fallback\n",
    "\n",
    "        start = 0\n",
    "        while start < len(c):\n",
    "            end = min(start + max_chunk_chars, len(c))\n",
    "            chunk = c[start:end].strip()\n",
    "            if len(chunk) >= min_len:\n",
    "                clean.append(chunk)\n",
    "            if end >= len(c):\n",
    "                break\n",
    "            start += step\n",
    "\n",
    "    return clean\n",
    "\n",
    "\n",
    "# ========== 3. ì €ì¥ í´ë” ì¤€ë¹„ ==========\n",
    "SAVE_DIR = Path(\"./chunk_preview_output\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_text(filename: str, content: str):\n",
    "    path = SAVE_DIR / filename\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return str(path)\n",
    "\n",
    "\n",
    "# ========== 4. ì „/í›„ ë¹„êµ + ì €ì¥ í•¨ìˆ˜ ==========\n",
    "def debug_preview_and_save(\n",
    "    data_dir: Path = DATA_DIR,\n",
    "    text_field: str = \"disease\",\n",
    "    max_chunk_chars: int = 1200,\n",
    "    min_len: int = 30,\n",
    "    overlap_chars: int = 200,\n",
    "    max_files: int = 2,\n",
    "    max_chunks_per_file: int = 3,\n",
    "):\n",
    "    pattern = str(data_dir / \"**\" / \"*.json\")\n",
    "    file_paths = glob.glob(pattern, recursive=True)\n",
    "\n",
    "    print(f\"[debug] JSON íŒŒì¼ {len(file_paths)}ê°œ ì¤‘ {max_files}ê°œ ë¯¸ë¦¬ë³´ê¸°\\n\")\n",
    "\n",
    "    for fp in file_paths[:max_files]:\n",
    "        print(\"#\" * 80)\n",
    "        print(f\"[FILE] {fp}\")\n",
    "\n",
    "        for obj in _iter_json(fp):\n",
    "            text = str(obj.get(text_field, \"\")).strip()\n",
    "            title = obj.get(\"title\", \"N/A\")\n",
    "            dept  = obj.get(\"department\", \"N/A\")\n",
    "\n",
    "            print(f\"  - title      : {title}\")\n",
    "            print(f\"  - department : {dept}\")\n",
    "            print(f\"  - text len   : {len(text)} chars\")\n",
    "\n",
    "            if not text:\n",
    "                print(\"  (âš ï¸ disease ë¹„ì–´ ìˆìŒ)\\n\")\n",
    "                continue\n",
    "\n",
    "            # ì €ì¥: ì›ë³¸\n",
    "            original_fname = Path(fp).stem + \"_original.txt\"\n",
    "            save_text(original_fname, text)\n",
    "\n",
    "            # ì²­í‚¹ ìˆ˜í–‰\n",
    "            chunks = _chunk_text(\n",
    "                text,\n",
    "                max_chunk_chars=max_chunk_chars,\n",
    "                min_len=min_len,\n",
    "                overlap_chars=overlap_chars,\n",
    "            )\n",
    "\n",
    "            # ì €ì¥: ì²­í¬\n",
    "            chunk_paths = []\n",
    "            for i, ch in enumerate(chunks):\n",
    "                chunk_name = f\"{Path(fp).stem}_chunk_{i}.txt\"\n",
    "                p = save_text(chunk_name, ch)\n",
    "                chunk_paths.append(p)\n",
    "\n",
    "            print(f\"  â†’ ì²­í¬ {len(chunks)}ê°œ ìƒì„±\")\n",
    "            print(f\"  â†’ ì›ë³¸ ì €ì¥: {original_fname}\")\n",
    "            print(f\"  â†’ ì²­í¬ ì €ì¥: {len(chunk_paths)}ê°œ (ì˜ˆ: {chunk_paths[:1]})\\n\")\n",
    "\n",
    "            # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Notebook ì¶œë ¥ (ì „/í›„ ë¹„êµ) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            print(\"-\" * 60)\n",
    "            print(\"[ì›ë³¸ text] (ì• 300ì)\")\n",
    "            print(text[:300] + (\"...\\n\" if len(text) > 300 else \"\\n\"))\n",
    "\n",
    "            print(\"[ì²­í¬ 0] (ì• 300ì)\")\n",
    "            if chunks:\n",
    "                print(chunks[0][:300] + (\"...\\n\" if len(chunks[0]) > 300 else \"\\n\"))\n",
    "\n",
    "            for i, ch in enumerate(chunks[:max_chunks_per_file]):\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"[CHUNK {i}] len={len(ch)}\")\n",
    "                print(ch[:400] + (\"\\n...\\n\" if len(ch) > 400 else \"\\n\"))\n",
    "\n",
    "# ========== 5. ì‹¤í–‰ ==========\n",
    "debug_preview_and_save(\n",
    "    data_dir=DATA_DIR,\n",
    "    text_field=\"disease\",\n",
    "    max_files=2,\n",
    "    max_chunks_per_file=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2ï¸âƒ£ Sentence-based Chunking (ë¬¸ì¥ ë‹¨ìœ„ + ê¸¸ì´ ì œí•œ)\n",
    "\n",
    "â†’ ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹, GPTê°€ ì²˜ë¦¬í•  ë•Œ ì˜¤ë¥˜ ì ìŒ\n",
    "\n",
    "âœ” íŠ¹ì§•\n",
    "\tâ€¢\të¬¸ì¥ì„ ê²½ê³„ë¡œ ìë¥´ê¸° ë•Œë¬¸ì— ì˜ë¯¸ íë¦„ì´ ìì—°ìŠ¤ëŸ½ë‹¤\n",
    "\tâ€¢\tKSS / spaCy / NLTK ë“± ë¬¸ì¥ ë¶„ë¦¬ê¸°ë¥¼ ì‚¬ìš©\n",
    "\tâ€¢\tâ€œê¹¨ë—í•œ ì˜ë¯¸ ë‹¨ìœ„â€ ìœ ì§€ë¨ â†’ QA ì •í™•ë„ â†‘\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\tìì—°ì–´ ì„¤ëª…ì´ ë§ì€ ë¬¸ì„œ\n",
    "\tâ€¢\të¬¸ì¥ ì¤‘ì‹¬ êµ¬ì¡°(ë¸”ë¡œê·¸, ì„¤ëª…ì„œ, ë¦¬í¬íŠ¸, êµê³¼ì„œ ë“±)\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\të¬¸ì¥ ë¶„ë¦¬ê°€ ëŠë¦´ ìˆ˜ ìˆìŒ\n",
    "\tâ€¢\tì¼ë¶€ ì–´ë ¤ìš´ ë¬¸ì¥ êµ¬ì¡°ì—ì„œ ë¶„ë¦¬ê°€ ì–´ìƒ‰í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3ï¸âƒ£ Paragraph-based Chunking (ë¹ˆ ì¤„ ê¸°ì¤€ ë¬¸ë‹¨ ì²­í‚¹)\n",
    "\n",
    "â†’ ë¬¸ë‹¨ì´ ê¹”ë”íˆ ì •ë¦¬ëœ ë¬¸ì„œì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥\n",
    "\n",
    "âœ” íŠ¹ì§•\n",
    "\tâ€¢\të¹ˆ ì¤„(\\n\\n) ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ì„ ìª¼ê°œê¸°\n",
    "\tâ€¢\të¬¸ë‹¨ ìì²´ê°€ ì˜ë¯¸ ë©ì–´ë¦¬ë¼ RAG ê²€ìƒ‰ í’ˆì§ˆ ê³ ì •\n",
    "\tâ€¢\të¬¸ì„œ êµ¬ì¡°ê°€ ê¹¨ë—í•œ ê²½ìš°ì—” ìµœì„ \n",
    "\tâ€¢\të³´í†µ PDF â†’ í…ìŠ¤íŠ¸ ë³€í™˜í˜• ë¬¸ì„œì—ì„œ ì •ë‹µ\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\têµê³¼ì„œ, ë³´ê³ ì„œ, ë§¤ë‰´ì–¼, ë…¼ë¬¸ (ë¬¸ë‹¨ ëª…í™•í•œ ê²½ìš°)\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\të„ˆì˜ ë°ì´í„°ì²˜ëŸ¼ ë¬¸ë‹¨ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš° â†’ 1ë©ì–´ë¦¬ë¡œ ë‚˜ì˜´\n",
    "\tâ€¢\t1ë¬¸ë‹¨ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì•¼ í•¨ â†’ ì†ì‹¤ ê°€ëŠ¥ì„±\n",
    "\n",
    "â¡ï¸ ê·¸ë˜ì„œ *â€œë¬¸ë‹¨ + ê¸¸ì´ ê¸°ë°˜ ì¡°í•©â€*ì´ ìì£¼ ì“°ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4ï¸âƒ£ Header-aware Chunking (ì œëª©/ì†Œì œëª© ê¸°ë°˜ ì²­í‚¹)\n",
    "\n",
    "â†’ ë¬¸ì„œ êµ¬ì¡°(ì„¹ì…˜)ê°€ í™•ì‹¤í•  ë•Œ ìµœê³  í’ˆì§ˆ\n",
    "\n",
    "âœ” íŠ¹ì§•\n",
    "\tâ€¢\tâ€œì œëª©/ì†Œì œëª©â€ì„ ê°ì§€í•˜ì—¬ ì„¹ì…˜ ë‹¨ìœ„ë¡œ ë¨¼ì € split\n",
    "\tâ€¢\tì˜ˆ:\n",
    "\tâ€¢\t### 1. Introduction\n",
    "\tâ€¢\t### Case 2 â€“ Diagnosis\n",
    "\tâ€¢\t2) ê²€ì‚¬í•­ëª©\n",
    "\tâ€¢\t- ì¦ìƒ ë“±\n",
    "\tâ€¢\tê° ì„¹ì…˜ ì•ˆì—ì„œ ë‹¤ì‹œ ê¸¸ì´ ê¸°ì¤€ ìŠ¬ë¼ì´ë”© ì ìš©\n",
    "\tâ€¢\têµ¬ì¡° + ë‚´ìš© ë‘˜ ë‹¤ ë³´ì¡´\n",
    "\n",
    "âœ” ì–¸ì œ ì¢‹ìŒ\n",
    "\tâ€¢\tê·œì¹™ ìˆëŠ” í…ìŠ¤íŠ¸ (ë§¤ë‰´ì–¼, ë³´ê³ ì„œ, ì—°êµ¬ ë¬¸ì„œ, ë©”ë‰´íŒ ë“±)\n",
    "\tâ€¢\tì œëª© íŒ¨í„´ì´ ëª…í™•í•œ JSON ë¼ë²¨ í˜•ì‹\n",
    "\n",
    "âœ” ë‹¨ì \n",
    "\tâ€¢\tì œëª© íŒ¨í„´ì„ ë§ì¶”ì§€ ëª»í•˜ë©´ split ì‹¤íŒ¨\n",
    "\tâ€¢\tì˜í•™ ì¦ë¡€ì²˜ëŸ¼ â€œë¬¸ë‹¨ì´ ë°”ë¡œ ë³¸ë¬¸ìœ¼ë¡œ ì‹œì‘â€í•˜ëŠ” ì¼€ì´ìŠ¤ëŠ” êµ¬ì¡°ê°€ ëœí•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
