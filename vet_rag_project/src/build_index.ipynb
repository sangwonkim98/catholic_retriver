{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ## 길이 슬라이딩 + overlap\n",
    "\n",
    "\t손실 없음, 안정적\n",
    "\t문장 중간 잘림\n",
    "\t논문/의학 증례\n",
    "\n",
    "2. ##  문장 기반 Sentence-based Chunking  -> kss, spacy, NLTK 문장분리기 \n",
    "(규칙 기반 + 문장 분리기)\n",
    "\n",
    "    ✔ 언제 좋음\n",
    "\t•\t자연어 설명이 많은 문서\n",
    "\t•\t문장 중심 구조(블로그, 설명서, 리포트, 교과서 등)\n",
    "\n",
    "✔ 단점\n",
    "\t•\t문장 분리가 느릴 수 있음\n",
    "\t•\t일부 어려운 문장 구조에서 분리가 어색할 수 있음\n",
    "\t\n",
    "\t\t##kss 내부 동작 구조(공식 문헌 기반)\n",
    "\t\t\t•\t한국어 종결 어미 규칙\n",
    "\t\t\t•\t마침표/따옴표/괄호 조합에 대한 룰\n",
    "\t\t\t•\t숫자/약어/리스트 표기 예외 처리\n",
    "\t\t\t•\t“다.”/“요.”/“했다.” 패턴 학습\n",
    "\t\t\t•\t문장 경계 후보를 놓고 통계 모델이 확률 판단\n",
    "\n",
    "\t\t즉:\n",
    "\n",
    "\t\tkss의 핵심 목표 = “문장이 어디서 끝나는지” 예측\n",
    "\n",
    "\t\t그리고 이 과정에서 길이, 의미, 슬라이딩 전혀 안 씀.\n",
    "\n",
    "3. 문단 기반\n",
    "    ✔ 특징\n",
    "\t•\t빈 줄(\\n\\n) 기준으로 문단을 쪼개기\n",
    "\t•\t문단 자체가 의미 덩어리라 RAG 검색 품질 고정\n",
    "\t•\t문서 구조가 깨끗한 경우엔 최선\n",
    "\t•\t보통 PDF → 텍스트 변환형 문서에서 정답\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t교과서, 보고서, 매뉴얼, 논문 (문단 명확한 경우)\n",
    "\n",
    "✔ 단점\n",
    "\t•\t너의 데이터처럼 문단이 거의 없는 경우 → 1덩어리로 나옴\n",
    "\t•\t1문단이 너무 길면 잘라야 함 → 손실 가능성\n",
    "\n",
    "\n",
    "4. 제목/헤더 기반\n",
    "    ✔ 특징\n",
    "\t•\t“제목/소제목”을 감지하여 섹션 단위로 먼저 split\n",
    "\t•\t예:\n",
    "\t•\t### 1. Introduction\n",
    "\t•\t### Case 2 – Diagnosis\n",
    "\t•\t2) 검사항목\n",
    "\t•\t- 증상 등\n",
    "\t•\t각 섹션 안에서 다시 길이 기준 슬라이딩 적용\n",
    "\t•\t구조 + 내용 둘 다 보존\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t규칙 있는 텍스트 (매뉴얼, 보고서, 연구 문서, 메뉴판 등)\n",
    "\t•\t제목 패턴이 명확한 JSON 라벨 형식\n",
    "\n",
    "✔ 단점\n",
    "\t•\t제목 패턴을 맞추지 못하면 split 실패\n",
    "\t•\t의학 증례처럼 “문단이 바로 본문으로 시작”하는 케이스는 구조가 덜함\n",
    "\n",
    "    \n",
    "## 5. 의미 기반(semantic)\n",
    " \n",
    "\n",
    " 1,2 순으로 적절하다.\n",
    " → 의미가 급격하게 바뀌는 지점을 자동 감지해 split\n",
    "\n",
    "✔ 특징\n",
    "\t•\t문장을 임베딩해서\n",
    "\t•\t이전 문장과 코사인 유사도 급하락 시 “새 청크 시작”\n",
    "\t•\t“토픽 전환 포인트”를 자동으로 인식\n",
    "\t•\t대규모 문서에서도 의미 일관성을 보장하는 최첨단 방식\n",
    "\t•\tLLM과의 궁합 완벽함\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t학술자료 / 여러 증례가 연속된 문서 / 매뉴얼 챕터 등\n",
    "\t•\t의미 덩어리를 스스로 이어야 하는 정교한 RAG 구축 시\n",
    "\n",
    "✔ 단점\n",
    "\t•\t가장 느림\n",
    "\t•\tsentence transformer 필요\n",
    "\t•\t구현 난이도 ↑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기본: 두 줄 이상 개행(빈 줄) 기준 분리 (r\"\\n{2,}\")\n",
    "#    - 너무 짧은/긴 조각 필터링 -> 실제 문서에서 손실률 너무큼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] JSON 파일 212개 중 2개 미리보기\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/응 과제해/자연어처리/rag/data/TS_말뭉치데이터_안과/0e8bca31-e151-11ef-4bb1-00155dced605.json\n",
      "  - title      : 40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "  - department : 안과\n",
      "  - text len   : 4526 chars\n",
      "  → 청크 1개 생성\n",
      "  → 원본 저장: 0e8bca31-e151-11ef-4bb1-00155dced605_original.txt\n",
      "  → 청크 저장: 1개 (예: ['chunk_preview_output/0e8bca31-e151-11ef-4bb1-00155dced605_chunk_0.txt'])\n",
      "\n",
      "------------------------------------------------------------\n",
      "[원본 text] (앞 300자)\n",
      "40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "10세 된 온전한 암컷 진돗개 한 마리가 1주일 동안 결막 충혈과 눈 분비물의 병력을 가지고 내원했습니다. 왼쪽 눈. 위협 반응, 눈부심 반사, 직접 동공 빛 반사가 없었하였다. 슬릿 램프 생체 현미경 각막 부종, 섬모 홍조, 수성 발적이 드러났하였다. 안구 내압은 68 mmHg였습니다. 이용 가능한 자료에 따르면, 녹내장과 포도막염 진단이 내려졌습니다. 안압 상승에 따른 시신경 손상. 사례 보고 미주리주 콜럼비아 65211, 미국 고니오디즈게네시스(goniodysgenesis), ...\n",
      "\n",
      "[청크 0] (앞 300자)\n",
      "40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "10세 된 온전한 암컷 진돗개 한 마리가 1주일 동안 결막 충혈과 눈 분비물의 병력을 가지고 내원했습니다. 왼쪽 눈. 위협 반응, 눈부심 반사, 직접 동공 빛 반사가 없었하였다. 슬릿 램프 생체 현미경 각막 부종, 섬모 홍조, 수성 발적이 드러났하였다. 안구 내압은 68 mmHg였습니다. 이용 가능한 자료에 따르면, 녹내장과 포도막염 진단이 내려졌습니다. 안압 상승에 따른 시신경 손상. 사례 보고 미주리주 콜럼비아 65211, 미국 고니오디즈게네시스(goniodysgenesis), ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 0] len=1200\n",
      "40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "10세 된 온전한 암컷 진돗개 한 마리가 1주일 동안 결막 충혈과 눈 분비물의 병력을 가지고 내원했습니다. 왼쪽 눈. 위협 반응, 눈부심 반사, 직접 동공 빛 반사가 없었하였다. 슬릿 램프 생체 현미경 각막 부종, 섬모 홍조, 수성 발적이 드러났하였다. 안구 내압은 68 mmHg였습니다. 이용 가능한 자료에 따르면, 녹내장과 포도막염 진단이 내려졌습니다. 안압 상승에 따른 시신경 손상. 사례 보고 미주리주 콜럼비아 65211, 미국 고니오디즈게네시스(goniodysgenesis), 후방 교착(pos terior synechia), 그리고 트라베큘라 망사(trabecular meshwork)의 색소 분산의 효과. 이것은 첫 번째 일차 보고입니다. 진돗개에서 선\n",
      "...\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/응 과제해/자연어처리/rag/data/TS_말뭉치데이터_안과/d24ea6b3-e150-11ef-bc07-00155dced605.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "SAVE_DIR = Path(\"./chunk_preview_output\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_text(filename: str, content: str):\n",
    "    path = SAVE_DIR / filename\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return str(path)\n",
    "def chunk_v1_paragraph(text, max_chunk_chars=1200, min_len=30):\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    raw_chunks = [c.strip() for c in re.split(r\"\\n{2,}\", text)]\n",
    "    clean = []\n",
    "    for c in raw_chunks:\n",
    "        if not c or len(c) < min_len:\n",
    "            continue\n",
    "        if len(c) > max_chunk_chars:\n",
    "            c = c[:max_chunk_chars]\n",
    "        clean.append(c)\n",
    "    return clean\n",
    "def debug_preview_and_save1(\n",
    "    data_dir: Path = DATA_DIR,\n",
    "    text_field: str = \"disease\",\n",
    "    max_chunk_chars: int = 1200,\n",
    "    min_len: int = 30,\n",
    "    max_files: int = 3,\n",
    "    max_chunks_per_file: int = 3,\n",
    "):\n",
    "    pattern = str(data_dir / \"**\" / \"*.json\")\n",
    "    file_paths = glob.glob(pattern, recursive=True)\n",
    "\n",
    "    print(f\"[debug] JSON 파일 {len(file_paths)}개 중 {max_files}개 미리보기\\n\")\n",
    "\n",
    "    for fp in file_paths[:max_files]:\n",
    "        print(\"#\" * 80)\n",
    "        print(f\"[FILE] {fp}\")\n",
    "\n",
    "        for obj in _iter_json(fp):\n",
    "            text = str(obj.get(text_field, \"\")).strip()\n",
    "            title = obj.get(\"title\", \"N/A\")\n",
    "            dept  = obj.get(\"department\", \"N/A\")\n",
    "\n",
    "            print(f\"  - title      : {title}\")\n",
    "            print(f\"  - department : {dept}\")\n",
    "            print(f\"  - text len   : {len(text)} chars\")\n",
    "\n",
    "            if not text:\n",
    "                print(\"  (⚠️ disease 비어 있음)\\n\")\n",
    "                continue\n",
    "\n",
    "            # 💾 원본 저장\n",
    "            original_name = Path(fp).stem + \"_original.txt\"\n",
    "            save_text(original_name, text)\n",
    "\n",
    "            chunks = chunk_v1_paragraph(text, max_chunk_chars=max_chunk_chars, min_len=min_len)\n",
    "\n",
    "            # 💾 각 청크 저장\n",
    "            chunk_paths = []\n",
    "            for i, ch in enumerate(chunks):\n",
    "                chunk_name = f\"{Path(fp).stem}_chunk_{i}.txt\"\n",
    "                p = save_text(chunk_name, ch)\n",
    "                chunk_paths.append(p)\n",
    "\n",
    "            print(f\"  → 청크 {len(chunks)}개 생성\")\n",
    "            print(f\"  → 원본 저장: {original_name}\")\n",
    "            print(f\"  → 청크 저장: {len(chunk_paths)}개 (예: {chunk_paths[:1]})\\n\")\n",
    "\n",
    "            # 🖥️ Notebook 전/후 비교 출력\n",
    "            print(\"-\" * 60)\n",
    "            print(\"[원본 text] (앞 300자)\")\n",
    "            print(text[:300] + (\"...\\n\" if len(text) > 300 else \"\\n\"))\n",
    "\n",
    "            print(\"[청크 0] (앞 300자)\")\n",
    "            if chunks:\n",
    "                print(chunks[0][:300] + (\"...\\n\" if len(chunks[0]) > 300 else \"\\n\"))\n",
    "\n",
    "            for i, ch in enumerate(chunks[:max_chunks_per_file]):\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"[CHUNK {i}] len={len(ch)}\")\n",
    "                print(ch[:400] + (\"\\n...\\n\" if len(ch) > 400 else \"\\n\"))\n",
    "                \n",
    "debug_preview_and_save1(\n",
    "    data_dir=DATA_DIR,\n",
    "    text_field=\"disease\",\n",
    "    max_files=2,\n",
    "    max_chunks_per_file=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 2.📐 알고리즘 구조\n",
    "\t1.\t텍스트 개행 정규화\n",
    "→ Windows/macOS 등 개행 차이를 제거하고 \\n으로 통일\n",
    "\t2.\t빈 줄(\\n\\n) 기준으로 문단을 1차 분리\n",
    "→ 긴 문서라도 최소한의 문단 구조는 유지\n",
    "\t3.\t각 문단에 대해:\n",
    "\t•\t길이가 1200자 이하면 그대로 사용\n",
    "\t•\t길이가 1200자 초과면\n",
    "→ 여러 개의 1200자 청크로 잘라냄\n",
    "→ 각 청크는 200자 정도 앞 청크의 끝부분을 겹쳐서(overlap) 포함\n",
    "\t4.\t모든 청크를 리스트로 반환\n",
    "→ 원본 내용 손실 없음 -->\n",
    "1️⃣ Length-based Sliding Window (길이 기반 + Overlap)\n",
    "\n",
    "→ 지금 네가 적용한 방식. 의학/논문형 텍스트에서 손실 없는 최강 기본기\n",
    "\n",
    "✔ 특징\n",
    "\t•\t줄바꿈/문단 구조가 엉망이거나 아예 없어도 안정적으로 작동\n",
    "\t•\t원본 손실 없음 (슬라이딩 윈도우로 모든 범위 커버)\n",
    "\t•\tRAG 검색 안정성 매우 좋음\n",
    "\t•\t구현 단순 + 전처리 속도 빠름\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t의학 증례 / 연구 보고서 / 논문형 텍스트\n",
    "\t•\tOCR / 웹크롤링처럼 문단 구조가 불명확한 텍스트\n",
    "\t•\t“지금 네 데이터 그대로”\n",
    "\n",
    "✔ 단점\n",
    "\t•\toverlap 때문에 청크 수가 늘어날 수 있음\n",
    "\t•\t문장 중간에서 끊길 수 있음\n",
    "\n",
    "max_chunk_chars=1200, overlap=200일 때:\n",
    "\t•\tCHUNK 0: 0 ~ 1200\n",
    "\t•\tCHUNK 1: 1000 ~ 2200\n",
    "\t•\tCHUNK 2: 2000 ~ 3200\n",
    "\t•\tCHUNK 3: 3000 ~ 4526\n",
    "\n",
    "\t문단 길이 = 2000자\n",
    "max = 800\n",
    "overlap = 200\n",
    "\n",
    "CHUNK1: 0~800\n",
    "CHUNK2: 600~1400\n",
    "CHUNK3: 1200~2000\n",
    "\n",
    "\t•\t보통 overlap_chars는 max_chunk_chars의 10~30% 정도가 무난:\n",
    "\t•\t1200이면 150~300 정도\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] JSON 파일 212개 중 2개 미리보기\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/응 과제해/자연어처리/rag/data/TS_말뭉치데이터_안과/0e8bca31-e151-11ef-4bb1-00155dced605.json\n",
      "  - title      : 40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "  - department : 안과\n",
      "  - text len   : 4526 chars\n",
      "  → 청크 5개 생성\n",
      "  → 원본 저장: 0e8bca31-e151-11ef-4bb1-00155dced605_original.txt\n",
      "  → 청크 저장: 5개 (예: ['chunk_preview_output2/0e8bca31-e151-11ef-4bb1-00155dced605_chunk_0.txt'])\n",
      "\n",
      "------------------------------------------------------------\n",
      "[원본 text] (앞 300자)\n",
      "40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "10세 된 온전한 암컷 진돗개 한 마리가 1주일 동안 결막 충혈과 눈 분비물의 병력을 가지고 내원했습니다. 왼쪽 눈. 위협 반응, 눈부심 반사, 직접 동공 빛 반사가 없었하였다. 슬릿 램프 생체 현미경 각막 부종, 섬모 홍조, 수성 발적이 드러났하였다. 안구 내압은 68 mmHg였습니다. 이용 가능한 자료에 따르면, 녹내장과 포도막염 진단이 내려졌습니다. 안압 상승에 따른 시신경 손상. 사례 보고 미주리주 콜럼비아 65211, 미국 고니오디즈게네시스(goniodysgenesis), ...\n",
      "\n",
      "[청크 0] (앞 300자)\n",
      "40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "10세 된 온전한 암컷 진돗개 한 마리가 1주일 동안 결막 충혈과 눈 분비물의 병력을 가지고 내원했습니다. 왼쪽 눈. 위협 반응, 눈부심 반사, 직접 동공 빛 반사가 없었하였다. 슬릿 램프 생체 현미경 각막 부종, 섬모 홍조, 수성 발적이 드러났하였다. 안구 내압은 68 mmHg였습니다. 이용 가능한 자료에 따르면, 녹내장과 포도막염 진단이 내려졌습니다. 안압 상승에 따른 시신경 손상. 사례 보고 미주리주 콜럼비아 65211, 미국 고니오디즈게네시스(goniodysgenesis), ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 0] len=1200\n",
      "40 .진돗개에서의 고니오디스게네시스 관련 녹내장\n",
      "10세 된 온전한 암컷 진돗개 한 마리가 1주일 동안 결막 충혈과 눈 분비물의 병력을 가지고 내원했습니다. 왼쪽 눈. 위협 반응, 눈부심 반사, 직접 동공 빛 반사가 없었하였다. 슬릿 램프 생체 현미경 각막 부종, 섬모 홍조, 수성 발적이 드러났하였다. 안구 내압은 68 mmHg였습니다. 이용 가능한 자료에 따르면, 녹내장과 포도막염 진단이 내려졌습니다. 안압 상승에 따른 시신경 손상. 사례 보고 미주리주 콜럼비아 65211, 미국 고니오디즈게네시스(goniodysgenesis), 후방 교착(pos terior synechia), 그리고 트라베큘라 망사(trabecular meshwork)의 색소 분산의 효과. 이것은 첫 번째 일차 보고입니다. 진돗개에서 선\n",
      "...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 1] len=1199\n",
      "안압 상승에 따른 시신경 손상. 10세 된 온전한 암컷 진돗개에 게 1주일간의 병력을 보고했습니다. 결막 충혈과 왼쪽 눈의 눈 분비물(OS). 내원 시, OS에서 안구염, 점액 분비물, 경미한 안검 경 련이 분명했하였다. 위협 반응, 눈부심 반사, 직접 동공 빛 반사 (PLR)은 OS에서 없었하였다. OS에서 오른쪽 눈(OD)으로 가는 간접 PLR은 또한 결여되어 있습니다. 슬릿램프 생체현미경(HS 7 000; Huvitz Co., Ltd., Korea)에서, OS에서 뚜렷한 상강막 혈관 주입, 확산성 각막 부종 및 각막 주위 섬모 홍조가 관찰되었으 며, 중등도(3+)의 플레어와 홍채 홍채 홍조증 및 홍채 봄베를 동반한 동공 확장증이 관찰되었 습니다. 플루오레세인 염색 각막 결함이 나타나지 않았하였다. IO\n",
      "...\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CHUNK 2] len=1200\n",
      "res Merck Sharp & Dohme Cibret, 프랑스; q8h), ii) 0.5% 레보플록사신(Cravit®; Santen Pharmaceutical 주식회사, 일본 오사카; q8h), 및 iii) 1% 프레드니솔론 아세테이트 (Pred Forte®; Allergan Pharmaceuticals, Ireland; q6h). OD의 예방적 치 료는 0.5% Betaxolol로 구성됨 (Betoptic®; Alc on couvreur NV, 벨기에 Puurs; q12h). 개는 첫 진료 후 1주일 후에 재검진을 받았하였다. 우리 병원에서. 주인은 첫 번째 진료와 비교했을 때 의미 있는 개선이 없다고 보고 했습니다. 집에서 국소 약물을 주입하는 데 어려움이 있었하였다. 핵출술이 권장되었습니다. 소유자의\n",
      "...\n",
      "\n",
      "################################################################################\n",
      "[FILE] /Users/test/응 과제해/자연어처리/rag/data/TS_말뭉치데이터_안과/d24ea6b3-e150-11ef-bc07-00155dced605.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Dict, Iterable\n",
    "\n",
    "# ========== 0. 데이터 경로 (너의 실제 경로) ==========\n",
    "DATA_DIR = Path(\"/Users/test/응 과제해/자연어처리/rag/data\")\n",
    "\n",
    "# ========== 1. JSON 읽기 ==========\n",
    "def _iter_json(file_path: str) -> Iterable[Dict]:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            obj = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            return\n",
    "    if isinstance(obj, dict):\n",
    "        yield obj\n",
    "    elif isinstance(obj, list):\n",
    "        for o in obj:\n",
    "            if isinstance(o, dict):\n",
    "                yield o\n",
    "\n",
    "\n",
    "# ========== 2. 손실 없는 청킹 함수 (overlap 포함) ==========\n",
    "def chunk_v2_overlap(text, max_chunk_chars=1200, min_len=30, overlap_chars=200):\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    raw_chunks = [c.strip() for c in re.split(r\"\\n{2,}\", text)]\n",
    "\n",
    "    clean = []\n",
    "    for c in raw_chunks:\n",
    "        if not c or len(c) < min_len:\n",
    "            continue\n",
    "\n",
    "        if len(c) <= max_chunk_chars:\n",
    "            clean.append(c)\n",
    "            continue\n",
    "\n",
    "        step = max_chunk_chars - overlap_chars\n",
    "        start = 0\n",
    "        while start < len(c):\n",
    "            end = min(start + max_chunk_chars, len(c))\n",
    "            chunk = c[start:end].strip()\n",
    "            if len(chunk) >= min_len:\n",
    "                clean.append(chunk)\n",
    "            if end >= len(c):\n",
    "                break\n",
    "            start += step\n",
    "    return clean\n",
    "\n",
    "# ========== 3. 저장 폴더 준비 ==========\n",
    "SAVE_DIR = Path(\"./chunk_preview_output2\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_text(filename: str, content: str):\n",
    "    path = SAVE_DIR / filename\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return str(path)\n",
    "\n",
    "\n",
    "# ========== 4. 전/후 비교 + 저장 함수 ==========\n",
    "def debug_preview_and_save2(\n",
    "    data_dir: Path = DATA_DIR,\n",
    "    text_field: str = \"disease\",\n",
    "    max_chunk_chars: int = 1200,\n",
    "    min_len: int = 30,\n",
    "    overlap_chars: int = 200,\n",
    "    max_files: int = 2,\n",
    "    max_chunks_per_file: int = 3,\n",
    "):\n",
    "    pattern = str(data_dir / \"**\" / \"*.json\")\n",
    "    file_paths = glob.glob(pattern, recursive=True)\n",
    "\n",
    "    print(f\"[debug] JSON 파일 {len(file_paths)}개 중 {max_files}개 미리보기\\n\")\n",
    "\n",
    "    for fp in file_paths[:max_files]:\n",
    "        print(\"#\" * 80)\n",
    "        print(f\"[FILE] {fp}\")\n",
    "\n",
    "        for obj in _iter_json(fp):\n",
    "            text = str(obj.get(text_field, \"\")).strip()\n",
    "            title = obj.get(\"title\", \"N/A\")\n",
    "            dept  = obj.get(\"department\", \"N/A\")\n",
    "\n",
    "            print(f\"  - title      : {title}\")\n",
    "            print(f\"  - department : {dept}\")\n",
    "            print(f\"  - text len   : {len(text)} chars\")\n",
    "\n",
    "            if not text:\n",
    "                print(\"  (⚠️ disease 비어 있음)\\n\")\n",
    "                continue\n",
    "\n",
    "            # 저장: 원본\n",
    "            original_fname = Path(fp).stem + \"_original.txt\"\n",
    "            save_text(original_fname, text)\n",
    "\n",
    "            # 청킹 수행\n",
    "            chunks = chunk_v2_overlap(\n",
    "                text,\n",
    "                max_chunk_chars=max_chunk_chars,\n",
    "                min_len=min_len,\n",
    "                overlap_chars=overlap_chars,\n",
    "            )\n",
    "\n",
    "            # 저장: 청크\n",
    "            chunk_paths = []\n",
    "            for i, ch in enumerate(chunks):\n",
    "                chunk_name = f\"{Path(fp).stem}_chunk_{i}.txt\"\n",
    "                p = save_text(chunk_name, ch)\n",
    "                chunk_paths.append(p)\n",
    "\n",
    "            print(f\"  → 청크 {len(chunks)}개 생성\")\n",
    "            print(f\"  → 원본 저장: {original_fname}\")\n",
    "            print(f\"  → 청크 저장: {len(chunk_paths)}개 (예: {chunk_paths[:1]})\\n\")\n",
    "\n",
    "            # ───────── Notebook 출력 (전/후 비교) ─────────\n",
    "            print(\"-\" * 60)\n",
    "            print(\"[원본 text] (앞 300자)\")\n",
    "            print(text[:300] + (\"...\\n\" if len(text) > 300 else \"\\n\"))\n",
    "\n",
    "            print(\"[청크 0] (앞 300자)\")\n",
    "            if chunks:\n",
    "                print(chunks[0][:300] + (\"...\\n\" if len(chunks[0]) > 300 else \"\\n\"))\n",
    "\n",
    "            for i, ch in enumerate(chunks[:max_chunks_per_file]):\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"[CHUNK {i}] len={len(ch)}\")\n",
    "                print(ch[:400] + (\"\\n...\\n\" if len(ch) > 400 else \"\\n\"))\n",
    "\n",
    "# ========== 5. 실행 ==========\n",
    "debug_preview_and_save2(\n",
    "    data_dir=DATA_DIR,\n",
    "    text_field=\"disease\",\n",
    "    max_files=2,\n",
    "    max_chunks_per_file=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ Sentence-based Chunking (문장 단위 + 길이 제한)\n",
    "\n",
    "→ 가장 자연스러운 방식, GPT가 처리할 때 오류 적음\n",
    "\n",
    "✔ 특징\n",
    "\t•\t문장을 경계로 자르기 때문에 의미 흐름이 자연스럽다\n",
    "\t•\tKSS / spaCy / NLTK 등 문장 분리기를 사용\n",
    "\t•\t“깨끗한 의미 단위” 유지됨 → QA 정확도 ↑\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t자연어 설명이 많은 문서\n",
    "\t•\t문장 중심 구조(블로그, 설명서, 리포트, 교과서 등)\n",
    "\n",
    "✔ 단점\n",
    "\t•\t문장 분리가 느릴 수 있음\n",
    "\t•\t일부 어려운 문장 구조에서 분리가 어색할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3️⃣ Paragraph-based Chunking (빈 줄 기준 문단 청킹)\n",
    "\n",
    "→ 문단이 깔끔히 정리된 문서에서 가장 좋은 성능\n",
    "\n",
    "✔ 특징\n",
    "\t•\t빈 줄(\\n\\n) 기준으로 문단을 쪼개기\n",
    "\t•\t문단 자체가 의미 덩어리라 RAG 검색 품질 고정\n",
    "\t•\t문서 구조가 깨끗한 경우엔 최선\n",
    "\t•\t보통 PDF → 텍스트 변환형 문서에서 정답\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t교과서, 보고서, 매뉴얼, 논문 (문단 명확한 경우)\n",
    "\n",
    "✔ 단점\n",
    "\t•\t너의 데이터처럼 문단이 거의 없는 경우 → 1덩어리로 나옴\n",
    "\t•\t1문단이 너무 길면 잘라야 함 → 손실 가능성\n",
    "\n",
    "➡️ 그래서 *“문단 + 길이 기반 조합”*이 자주 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4️⃣ Header-aware Chunking (제목/소제목 기반 청킹)\n",
    "\n",
    "→ 문서 구조(섹션)가 확실할 때 최고 품질\n",
    "\n",
    "✔ 특징\n",
    "\t•\t“제목/소제목”을 감지하여 섹션 단위로 먼저 split\n",
    "\t•\t예:\n",
    "\t•\t### 1. Introduction\n",
    "\t•\t### Case 2 – Diagnosis\n",
    "\t•\t2) 검사항목\n",
    "\t•\t- 증상 등\n",
    "\t•\t각 섹션 안에서 다시 길이 기준 슬라이딩 적용\n",
    "\t•\t구조 + 내용 둘 다 보존\n",
    "\n",
    "✔ 언제 좋음\n",
    "\t•\t규칙 있는 텍스트 (매뉴얼, 보고서, 연구 문서, 메뉴판 등)\n",
    "\t•\t제목 패턴이 명확한 JSON 라벨 형식\n",
    "\n",
    "✔ 단점\n",
    "\t•\t제목 패턴을 맞추지 못하면 split 실패\n",
    "\t•\t의학 증례처럼 “문단이 바로 본문으로 시작”하는 케이스는 구조가 덜함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
